{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum Generative Adversarial Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A QGAN is the quantum version of a *Generative Adversarial Network*. These are a particular kind of deep learning model used to generate real-looking synthetic data (such as images)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/biggan.png\" width=600px></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GANs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> GANs have a unique structure, consisting of two models:\n",
    "\n",
    "> - the **generator**: its goal is to produce realistic-looking data samples\n",
    "\n",
    "> - the **discriminator**: its goal is distinguish fake data produced by the generator from real data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training of GANs proceeds as follows:\n",
    "\n",
    "1. \"Real\" data is captured in some *training dataset*.\n",
    "\n",
    "2. The *generator* produces \"fake\" data by starting with a random input vector and transforming it into an output.\n",
    "\n",
    "3. The *discriminator* is fed samples of both real and fake data and must decide which label to assign ('real' or 'fake').\n",
    "\n",
    "4. Training consists of alternating steps: (i) the generator is frozen and the discriminator is trained to distinguish real from fake. (ii) the discriminator is frozen and the generator is trained to fool the discriminator. The gradient of the discriminator's output provides a training signal for the generator to improve its fake generated data. \n",
    "\n",
    "5. Eventually, this training method should converge to a stage where the generator is producing realistic data and the discriminator can't tell real from fake.\n",
    "\n",
    "**Note:** Training is done via the *gradient descent* algorithm, updating only the weights associated with the generator (or vice versa) at each step. There is no internal structure imposed on the generator or discriminator models except that they are differentiable."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/gan.png\" width=600px></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qauntum GANs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This demo walks through how to build and train a simple Quantum Generative Adversarial Network (QGAN) using PennyLane. Like classical GANs, QGANs consist of a generator and a discriminator. **QGANs use variational quantum circuits for both generator and discriminator.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References: \n",
    "\n",
    "- [Lloyd and Weedbrook (2018)](https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.121.040502) \n",
    "\n",
    "\n",
    "- [Dallaire-Demers and Killoran (2018)](https://journals.aps.org/pra/abstract/10.1103/PhysRevA.98.012324)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** One of the areas where QGANs can provide a clear advantage is in modelling *quantum data*, i.e., data that is created by quantum systems. Quantum data distributions may be hard for classical models to emulate efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PennyLane Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first import the essentials\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a device for the QGAN example\n",
    "gan_dev = qml.device('default.qubit', wires=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this QGAN example, we will use a quantum circuit to generate the real data- a qubit that has been rotated (from the starting state $\\mid0\\rangle$) to some arbitrary but fixed state. We will use the PennyLane [Rot](https://pennylane.readthedocs.io/en/latest/code/ops/qubit.html#pennylane.ops.qubit.Rot) operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real(phi, theta, omega):\n",
    "    qml.Rot(phi, theta, omega, wires=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the generator and discriminator, we will choose the same basic circuit structure, but acting on different wires:\n",
    "\n",
    "- Both the real data circuit and the generator will output on wire 0\n",
    "- Wire 0 will be connected as an input to the discriminator\n",
    "- Wire 1 is provided as a workspace for the generator\n",
    "- The discriminator's output will be on wire 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: the structure of these circuits is more-or-less chosen arbitrarily. There is \n",
    "# nothing particular about these choices of generator or discriminator\n",
    "\n",
    "def generator(w):\n",
    "    qml.RX(w[0], wires=0)\n",
    "    qml.RX(w[1], wires=1)\n",
    "    qml.RY(w[2], wires=0)\n",
    "    qml.RY(w[3], wires=1)\n",
    "    qml.RZ(w[4], wires=0)\n",
    "    qml.RZ(w[5], wires=1)\n",
    "    qml.CNOT(wires=[0,1])\n",
    "    qml.RX(w[6], wires=0)\n",
    "    qml.RY(w[7], wires=0)\n",
    "    qml.RZ(w[8], wires=0)\n",
    "    \n",
    "def discriminator(w):\n",
    "    qml.RX(w[0], wires=0)\n",
    "    qml.RX(w[1], wires=2)\n",
    "    qml.RY(w[2], wires=0)\n",
    "    qml.RY(w[3], wires=2)\n",
    "    qml.RZ(w[4], wires=0)\n",
    "    qml.RZ(w[5], wires=2)\n",
    "    qml.CNOT(wires=[1,2])\n",
    "    qml.RX(w[6], wires=2)\n",
    "    qml.RY(w[7], wires=2)\n",
    "    qml.RZ(w[8], wires=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create two `QNodes`. One where the real data source is wired up to the discriminator and another where the generator is connected to the discriminator. They can both be run on the same device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(gan_dev)\n",
    "def real_disc_circuit(phi, theta, omega, disc_weights):\n",
    "    real(phi, theta, omega)\n",
    "#    discriminator(disc_weights)\n",
    "    return qml.expval.PauliZ(2)\n",
    "\n",
    "@qml.qnode(gan_dev)\n",
    "def gen_disc_circuit(gen_weights, disc_weights):\n",
    "    generator(gen_weights)\n",
    "    discriminator(disc_weights)\n",
    "    return qml.expval.PauliZ(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cost function\n",
    "\n",
    "There are two ingredients to the cost here:\n",
    "\n",
    "1. the probability that the discriminator correctly **classifies real data as real.** \n",
    "2. the probability that the discriminator **classifies fake data (i.e., a state prepared by the generator) as real.** \n",
    "\n",
    "The discriminator's objective is to maximize the probability of correctly classifying real data, while minimizing the probability of mistakenly classifying fake data.\n",
    "\n",
    "The generator's objective is to maximize the probability that the discriminator accepts fake data as real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_real_true(disc_weights):\n",
    "    true_disc_output = real_disc_circuit(phi, theta, omega, disc_weights)\n",
    "    # convert from expectation of Pauli-Z [-1,1] to probability [0,1] \n",
    "    prob_real_true = (true_disc_output + 1) / 2\n",
    "    return prob_real_true\n",
    "\n",
    "def prob_fake_true(gen_weights, disc_weights):\n",
    "    fake_disc_output = gen_disc_circuit(gen_weights, disc_weights)\n",
    "    # convert from expectation of Pauli-Z [-1,1] to probability [0,1]\n",
    "    prob_fake_true = (fake_disc_output + 1) / 2\n",
    "    return prob_fake_true # generator wants to minimize this prob\n",
    "\n",
    "def disc_cost(disc_weights):\n",
    "    cost = prob_fake_true(gen_weights, disc_weights) - prob_real_true(disc_weights) \n",
    "    return cost\n",
    "# this ensures that prob_fake_true is minimized and prob_real_true is\n",
    "# maximized to get the minimum (largest negative 0-1=-1) cost\n",
    "\n",
    "def gen_cost(gen_weights):\n",
    "    return -prob_fake_true(gen_weights, disc_weights) \n",
    "# -ve sign ensures that gen_cost is minimum when prob_fake_true is close\n",
    "# to 1 and the generator was able to fool the discriminator as intended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Optimization \n",
    "\n",
    "We initialize the fixed angles of the \"real data\" circuit as well as the initial parameters for both generator and discriminator. These are chosen so that the generator initially prepares a state on wire 0 that is very close to the $\\mid1\\rangle$ state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = np.pi / 6\n",
    "theta = np.pi / 2\n",
    "omega = np.pi / 7\n",
    "np.random.seed(1)\n",
    "eps = 1e-2\n",
    "gen_weights = np.array([np.pi] + [0] * 8) + np.random.normal(scale=eps, size=[9])\n",
    "disc_weights = np.random.normal(size=[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an optimizer\n",
    "opt = qml.GradientDescentOptimizer(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first stage of training, we optimize the discriminator while keeping the generator parameters fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: cost = -0.6968864120481895\n",
      "Step 6: cost = -0.8833291170857082\n",
      "Step 11: cost = -0.9622277873352207\n",
      "Step 16: cost = -0.9884645281702815\n",
      "Step 21: cost = -0.9964573315639257\n",
      "Step 26: cost = -0.9988464239391739\n",
      "Step 31: cost = -0.9995681172734079\n",
      "Step 36: cost = -0.9997922603205729\n",
      "Step 41: cost = -0.9998648143641096\n",
      "Step 46: cost = -0.9998895581303086\n"
     ]
    }
   ],
   "source": [
    "for it in range(50):\n",
    "    disc_weights = opt.step(disc_cost, disc_weights) \n",
    "    cost = disc_cost(disc_weights)\n",
    "    if it % 5 == 0:\n",
    "        print(\"Step {}: cost = {}\".format(it+1, cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the discriminator's optimum, the probability for the discriminator to correctly classify the real data should be close to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_real_true(disc_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, we check how the discriminator classifies the generator's (still unoptimized) fake data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00010266209557718842"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_fake_true(gen_weights, disc_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the adverserial training method, we have to now train the generator to better fool the discriminator.\n",
    "\n",
    "In more complex settings, we can continue training the models in an alternating fashion until we reach the optimum point of the two-player adversarial game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: cost = 0.00011107868092574691\n",
      "Step 5: cost = 0.00016565521511247017\n",
      "Step 10: cost = 0.00024883127273001016\n",
      "Step 15: cost = 0.000375571952737519\n",
      "Step 20: cost = 0.0005686442459871266\n",
      "Step 25: cost = 0.0008626464448956428\n",
      "Step 30: cost = 0.0013100684881506286\n",
      "Step 35: cost = 0.001990340855148154\n",
      "Step 40: cost = 0.003023193633626464\n",
      "Step 45: cost = 0.004588029831785467\n",
      "Step 50: cost = 0.006951225025853658\n",
      "Step 55: cost = 0.010502797801980712\n",
      "Step 60: cost = 0.015801642050431164\n",
      "Step 65: cost = 0.023622380634211848\n",
      "Step 70: cost = 0.03498385472862875\n",
      "Step 75: cost = 0.051117422146382985\n",
      "Step 80: cost = 0.0733093341013975\n",
      "Step 85: cost = 0.10255490845689808\n",
      "Step 90: cost = 0.13904896781140308\n",
      "Step 95: cost = 0.1817321615584001\n",
      "Step 100: cost = 0.2282784068984718\n",
      "Step 105: cost = 0.2757529771643312\n",
      "Step 110: cost = 0.32166087289133827\n",
      "Step 115: cost = 0.3647571877240606\n",
      "Step 120: cost = 0.4052267448896536\n",
      "Step 125: cost = 0.444327180897534\n",
      "Step 130: cost = 0.48379523593280693\n",
      "Step 135: cost = 0.5252112437473836\n",
      "Step 140: cost = 0.5693871982389012\n",
      "Step 145: cost = 0.6158707405857196\n",
      "Step 150: cost = 0.662798743611954\n",
      "Step 155: cost = 0.707352461566613\n",
      "Step 160: cost = 0.7467385082942217\n",
      "Step 165: cost = 0.7791569786278929\n",
      "Step 170: cost = 0.8041891769887488\n",
      "Step 175: cost = 0.8225327898093195\n",
      "Step 180: cost = 0.8354482536908572\n",
      "Step 185: cost = 0.8442820477528026\n",
      "Step 190: cost = 0.8502030968985819\n",
      "Step 195: cost = 0.8541176291218314\n"
     ]
    }
   ],
   "source": [
    "for it in range(200):\n",
    "    gen_weights = opt.step(gen_cost, gen_weights)\n",
    "    cost = -gen_cost(gen_weights)\n",
    "    if it % 5 == 0:\n",
    "        print(\"Step {}: cost = {}\".format(it, cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the optimum of the generator, the probability for the discriminator to be fooled should be close to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_real_true(disc_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8562528122970663"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_fake_true(gen_weights, disc_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the joint optimum the overall cost will be close to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1437471877029337"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc_cost(disc_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generator has successfully learned how to simulate the real data enough to fool the discriminator!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
